{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenAiGym-MountainCar",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPJUlBK8D4I0JtaMvWzsJK/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robot-ai-working-group/google-colaboratory-env/blob/main/OpenAiGym_MountainCar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfUWdWkBMoLD"
      },
      "source": [
        "# Open Ai Gym on Google colaboratry\n",
        "\n",
        "## 環境作成\n",
        "\n",
        "### library install\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqr_PFZIPAi-",
        "outputId": "b6b00efa-c85b-45bb-b0f8-3b9e84daa5a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!apt-get -qq -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1 > /dev/null\n",
        "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
        " \n",
        "!apt-get -qq -y install xvfb freeglut3-dev ffmpeg> /dev/null\n",
        "!pip install pyglet\n",
        "!pip install pyopengl\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install gym[classic_control]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Unable to locate package libcusparse8.0\n",
            "E: Couldn't find any package by glob 'libcusparse8.0'\n",
            "E: Couldn't find any package by regex 'libcusparse8.0'\n",
            "E: Unable to locate package libnvrtc8.0\n",
            "E: Couldn't find any package by glob 'libnvrtc8.0'\n",
            "E: Couldn't find any package by regex 'libnvrtc8.0'\n",
            "Requirement already satisfied: pyglet in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet) (0.16.0)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.6/dist-packages (3.1.5)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.6/dist-packages (from pyvirtualdisplay) (0.3)\n",
            "Requirement already satisfied: gym[classic_control] in /usr/local/lib/python3.6/dist-packages (0.17.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[classic_control]) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[classic_control]) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[classic_control]) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[classic_control]) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[classic_control]) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZye0yuPPryZ"
      },
      "source": [
        "### virtual displayの設定\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN1F1W42QCat"
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1024, 768))\n",
        "display.start()\n",
        "import os\n",
        " \n",
        " \n",
        "# Error になるのでコメント化\n",
        "# os.environ[\"DISPLAY\"] = \":\" + str(display.display) + \".\" + str(display.screen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIUw1aZLMmTU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jLizbICfzBd"
      },
      "source": [
        "## Google Drive へマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT0aBPQHgV9Y",
        "outputId": "aa1c95ab-d661-44ff-df76-1c1f8a2d6110",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OccaplOmIVNq"
      },
      "source": [
        "### データ保存用ディレクトリの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-Ofg3ETH_Wi",
        "outputId": "8f53b4dc-5eca-43ad-d8b8-4c6eb6c2bcd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%mkdir \"/content/drive/My Drive/Colab Notebooks/OpenAiGym\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/My Drive/Colab Notebooks/OpenAiGym’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OZlrHaEhyIt",
        "outputId": "3c0854e2-9359-4cdd-9213-9f1ea22d4243",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/OpenAiGym"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/OpenAiGym\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6xELjp5hZPf"
      },
      "source": [
        "## git 連携\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCfKjXmDiByT",
        "outputId": "f3543a8b-95e8-4ab1-d000-a6e706cb3642",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/robot-ai-working-group/google-colaboratory-env.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'google-colaboratory-env'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_AmmvB2ivPQ"
      },
      "source": [
        "!git config --global user.email \"yadamon4inoue@gmail.com\"\n",
        "!git config --global user.name \"peeeechi\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki1nVQW_HGdQ"
      },
      "source": [
        "## Sample を動かす"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xfpzAnFQZUX"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import json, os\n",
        " \n",
        " \n",
        "def get_status(_observation):\n",
        "    env_low = env.observation_space.low # 位置と速度の最小値\n",
        "    env_high = env.observation_space.high # 位置と速度の最大値\n",
        "    env_dx = (env_high - env_low) / 40 # 40等分\n",
        "    # 0〜39の離散値に変換する\n",
        "    position = int((_observation[0] - env_low[0])/env_dx[0])\n",
        "    velocity = int((_observation[1] - env_low[1])/env_dx[1])\n",
        "    return position, velocity\n",
        " \n",
        "def update_q_table(_q_table, _action,  _observation, _next_observation, _reward, _episode):\n",
        " \n",
        "    alpha = 0.2 # 学習率\n",
        "    gamma = 0.99 # 時間割引き率\n",
        " \n",
        "    # 行動後の状態で得られる最大行動価値 Q(s',a')\n",
        "    next_position, next_velocity = get_status(_next_observation)\n",
        "    next_max_q_value = max(_q_table[next_position][next_velocity])\n",
        " \n",
        "    # 行動前の状態の行動価値 Q(s,a)\n",
        "    position, velocity = get_status(_observation)\n",
        "    q_value = _q_table[position][velocity][_action]\n",
        " \n",
        "    # 行動価値関数の更新\n",
        "    _q_table[position][velocity][_action] = q_value + alpha * (_reward + gamma * next_max_q_value - q_value)\n",
        " \n",
        "    return _q_table\n",
        " \n",
        "def get_action(_env, _q_table, _observation, _episode):\n",
        "    epsilon = 0.002\n",
        "    if np.random.uniform(0, 1) > epsilon:\n",
        "        position, velocity = get_status(observation)\n",
        "        _action = np.argmax(_q_table[position][velocity])\n",
        "    else:\n",
        "        _action = np.random.choice([0, 1, 2])\n",
        "    return _action"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D2Wd_0mTPNF"
      },
      "source": [
        "def writeParam(filename, param):\n",
        "    with open(filename, 'w', encoding='utf-8') as wf:\n",
        "        json.dump(param, wf, indent=2)\n",
        "\n",
        "def readParam(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as rf:\n",
        "        param = json.load(rf)\n",
        "    \n",
        "    return param"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iID8PB3YQdyw",
        "outputId": "5613f1e0-ddda-4df8-b798-3b8c02040fc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "env = gym.make('MountainCar-v0')\n",
        "\n",
        "paramFile = \"param.json\"\n",
        "\n",
        "\n",
        "if (os.path.exists(paramFile)):\n",
        "    array = np.array(readParam(paramFile))\n",
        "    q_table =  array.reshape([40, 40, 3])\n",
        "else:\n",
        "    # Qテーブルの初期化\n",
        "    q_table = np.zeros((40, 40, 3))\n",
        " \n",
        "observation = env.reset()\n",
        "rewards = []\n",
        " \n",
        "# 10000エピソードで学習する\n",
        "for episode in range(10000):\n",
        " \n",
        "    total_reward = 0\n",
        "    observation = env.reset()\n",
        " \n",
        "    for _ in range(200):\n",
        " \n",
        "        # ε-グリーディ法で行動を選択\n",
        "        action = get_action(env, q_table, observation, episode)\n",
        " \n",
        "        # if episode%1000 == 0:\n",
        "            # env.render()\n",
        " \n",
        "        # 車を動かし、観測結果・報酬・ゲーム終了FLG・詳細情報を取得\n",
        "        next_observation, reward, done, _ = env.step(action)\n",
        " \n",
        "        # Qテーブルの更新\n",
        "        q_table = update_q_table(q_table, action, observation, next_observation, reward, episode)\n",
        "        total_reward += reward\n",
        " \n",
        "        observation = next_observation\n",
        " \n",
        "        if done:\n",
        "            # doneがTrueになったら１エピソード終了\n",
        "            if episode%100 == 0:\n",
        "                print('episode: {}, total_reward: {}'.format(episode, total_reward))\n",
        "            rewards.append(total_reward)\n",
        "            writeParam(filename=paramFile, param=list(q_table.flatten()))\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode: 0, total_reward: -131.0\n",
            "episode: 100, total_reward: -138.0\n",
            "episode: 200, total_reward: -136.0\n",
            "episode: 300, total_reward: -134.0\n",
            "episode: 400, total_reward: -137.0\n",
            "episode: 500, total_reward: -130.0\n",
            "episode: 600, total_reward: -120.0\n",
            "episode: 700, total_reward: -135.0\n",
            "episode: 800, total_reward: -140.0\n",
            "episode: 900, total_reward: -114.0\n",
            "episode: 1000, total_reward: -137.0\n",
            "episode: 1100, total_reward: -140.0\n",
            "episode: 1200, total_reward: -132.0\n",
            "episode: 1300, total_reward: -137.0\n",
            "episode: 1400, total_reward: -143.0\n",
            "episode: 1500, total_reward: -134.0\n",
            "episode: 1600, total_reward: -131.0\n",
            "episode: 1700, total_reward: -112.0\n",
            "episode: 1800, total_reward: -138.0\n",
            "episode: 1900, total_reward: -110.0\n",
            "episode: 2000, total_reward: -135.0\n",
            "episode: 2100, total_reward: -117.0\n",
            "episode: 2200, total_reward: -136.0\n",
            "episode: 2300, total_reward: -121.0\n",
            "episode: 2400, total_reward: -200.0\n",
            "episode: 2500, total_reward: -113.0\n",
            "episode: 2600, total_reward: -132.0\n",
            "episode: 2700, total_reward: -121.0\n",
            "episode: 2800, total_reward: -137.0\n",
            "episode: 2900, total_reward: -136.0\n",
            "episode: 3000, total_reward: -111.0\n",
            "episode: 3100, total_reward: -112.0\n",
            "episode: 3200, total_reward: -113.0\n",
            "episode: 3300, total_reward: -111.0\n",
            "episode: 3400, total_reward: -111.0\n",
            "episode: 3500, total_reward: -135.0\n",
            "episode: 3600, total_reward: -136.0\n",
            "episode: 3700, total_reward: -108.0\n",
            "episode: 3800, total_reward: -136.0\n",
            "episode: 3900, total_reward: -192.0\n",
            "episode: 4000, total_reward: -122.0\n",
            "episode: 4100, total_reward: -137.0\n",
            "episode: 4200, total_reward: -134.0\n",
            "episode: 4300, total_reward: -140.0\n",
            "episode: 4400, total_reward: -108.0\n",
            "episode: 4500, total_reward: -140.0\n",
            "episode: 4600, total_reward: -134.0\n",
            "episode: 4700, total_reward: -121.0\n",
            "episode: 4800, total_reward: -123.0\n",
            "episode: 4900, total_reward: -112.0\n",
            "episode: 5000, total_reward: -136.0\n",
            "episode: 5100, total_reward: -135.0\n",
            "episode: 5200, total_reward: -135.0\n",
            "episode: 5300, total_reward: -139.0\n",
            "episode: 5400, total_reward: -137.0\n",
            "episode: 5500, total_reward: -112.0\n",
            "episode: 5600, total_reward: -109.0\n",
            "episode: 5700, total_reward: -112.0\n",
            "episode: 5800, total_reward: -136.0\n",
            "episode: 5900, total_reward: -141.0\n",
            "episode: 6000, total_reward: -142.0\n",
            "episode: 6100, total_reward: -114.0\n",
            "episode: 6200, total_reward: -200.0\n",
            "episode: 6300, total_reward: -117.0\n",
            "episode: 6400, total_reward: -178.0\n",
            "episode: 6500, total_reward: -116.0\n",
            "episode: 6600, total_reward: -145.0\n",
            "episode: 6700, total_reward: -123.0\n",
            "episode: 6800, total_reward: -147.0\n",
            "episode: 6900, total_reward: -183.0\n",
            "episode: 7000, total_reward: -154.0\n",
            "episode: 7100, total_reward: -149.0\n",
            "episode: 7200, total_reward: -140.0\n",
            "episode: 7300, total_reward: -150.0\n",
            "episode: 7400, total_reward: -148.0\n",
            "episode: 7500, total_reward: -126.0\n",
            "episode: 7600, total_reward: -143.0\n",
            "episode: 7700, total_reward: -141.0\n",
            "episode: 7800, total_reward: -133.0\n",
            "episode: 7900, total_reward: -133.0\n",
            "episode: 8000, total_reward: -145.0\n",
            "episode: 8100, total_reward: -119.0\n",
            "episode: 8200, total_reward: -176.0\n",
            "episode: 8300, total_reward: -127.0\n",
            "episode: 8400, total_reward: -154.0\n",
            "episode: 8500, total_reward: -144.0\n",
            "episode: 8600, total_reward: -128.0\n",
            "episode: 8700, total_reward: -144.0\n",
            "episode: 8800, total_reward: -139.0\n",
            "episode: 8900, total_reward: -136.0\n",
            "episode: 9000, total_reward: -163.0\n",
            "episode: 9100, total_reward: -117.0\n",
            "episode: 9200, total_reward: -143.0\n",
            "episode: 9300, total_reward: -128.0\n",
            "episode: 9400, total_reward: -128.0\n",
            "episode: 9500, total_reward: -144.0\n",
            "episode: 9600, total_reward: -143.0\n",
            "episode: 9700, total_reward: -139.0\n",
            "episode: 9800, total_reward: -142.0\n",
            "episode: 9900, total_reward: -116.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T39d_SLAWl-L"
      },
      "source": [
        "# 新しいセクション"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioNsOZ2DJuYj",
        "outputId": "217b6457-d879-4146-ea85-e000e7865bba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git add -A"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "warning: adding embedded git repository: OpenAiGym-on-GoogleColabratory\n",
            "hint: You've added another git repository inside your current repository.\n",
            "hint: Clones of the outer repository will not contain the contents of\n",
            "hint: the embedded repository and will not know how to obtain it.\n",
            "hint: If you meant to add a submodule, use:\n",
            "hint: \n",
            "hint: \tgit submodule add <url> OpenAiGym-on-GoogleColabratory\n",
            "hint: \n",
            "hint: If you added this path by mistake, you can remove it from the\n",
            "hint: index with:\n",
            "hint: \n",
            "hint: \tgit rm --cached OpenAiGym-on-GoogleColabratory\n",
            "hint: \n",
            "hint: See \"git help submodule\" for more information.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvmfh1x8K1JX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywcgG8VELzTq"
      },
      "source": [
        "# 新しいセクション"
      ]
    }
  ]
}